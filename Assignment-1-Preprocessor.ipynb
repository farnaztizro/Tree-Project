{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a32840b-f217-49cc-9567-5a31e02fe14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36048dd-2584-4381-9120-d791c2f85f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albuquerque', 'Anaheim', 'Arlington', 'Atlanta', 'Aurora', 'Austin', 'Baltimore', 'Boston', 'Buffalo', 'CapeCoral', 'ColoradoSprings', 'Columbus', 'Dallas', 'Denver', 'DesMoines', 'Detroit', 'Durham', 'Fresno', 'GardenGrove', 'GrandRapids', 'Greensboro', 'Honolulu', 'Houston', 'HuntingtonBeach', 'Indianapolis', 'Irvine', 'Jerseycity', 'Knoxville', 'LasVegas', 'LosAngeles', 'Louisville', 'Madison', 'Miami', 'Milwaukee', 'Minneapolis', 'Nashville', 'NewOrleans', 'NewYork', 'Oakland', 'OklahomaCity', 'Ontario', 'Orlando', 'OverlandPark', 'Phoenix', 'Pittsburgh', 'Plano', 'Portland', 'Providence', 'RanchoCucamonga', 'Richmond', 'Rochester', 'Sacramento', 'SanDiego', 'SanFrancisco', 'SanJose', 'SantaRosa', 'Seattle', 'SiouxFalls', 'StLouis', 'Stockton', 'Tampa', 'WashingtonDC', 'Worcester']\n"
     ]
    }
   ],
   "source": [
    "#Get filenames from the directory for setting up the dropdown.\n",
    "\n",
    "FullFilenames = (glob.glob(\"Dataset/*.csv\"))\n",
    "OnlyFilenames = []\n",
    "for i in FullFilenames:\n",
    "    SplitOnUnderscores = i.split('_')\n",
    "    SplitOnSlash = SplitOnUnderscores[0].split('\\\\')\n",
    "    filename = SplitOnSlash[1]\n",
    "    OnlyFilenames.append(filename)\n",
    "print(OnlyFilenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59792422-c189-4c51-b8e5-45b15a445fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scientific_name', 'common_name', 'city', 'state']\n"
     ]
    }
   ],
   "source": [
    "# insert the names of columns you wish to extract Intresting columns are \n",
    "# the ones for which we will visualise the data. If all rows of any intresting columns have null values we will drop the data file.\n",
    "\n",
    "IntrestingColumns = ['scientific_name','common_name','city','state'] \n",
    "print(IntrestingColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6520776-e031-4163-aba0-61e645e741f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a processor for a bar graphs section 1.\n",
    "# We will be removing those trees from dataset whose count is less than 50 so visualization can be better.\n",
    "def processFile(city):\n",
    "    Filename = (glob.glob(\"Dataset/\" + city + \"*.csv\"))\n",
    "    data = pd.read_csv(Filename[0], usecols=IntrestingColumns) #use nrows paramter to limit the data if it consumes too much time to process\n",
    "    data.dropna(how='any', inplace=True)\n",
    "    if(not(data.empty)):\n",
    "        # Create a list of dictionaries for each tree species in the city\n",
    "        city_tree_data = []\n",
    "        \n",
    "        # Group data by scientific_name and get the count\n",
    "        tree_counts = data['scientific_name'].value_counts().to_dict()\n",
    "        \n",
    "        # Extract city and state information\n",
    "        city_info = data.iloc[0][['city', 'state']].to_dict()\n",
    "    \n",
    "        for scientific_name, count in tree_counts.items():\n",
    "            common_names = data[data['scientific_name'] == scientific_name]['common_name'].unique().tolist()\n",
    "            if(count>50):\n",
    "                city_tree_data.append({\n",
    "                    'scientific_name': scientific_name,\n",
    "                    'common_name': common_names,\n",
    "                    'count': count,\n",
    "                    \"city\" : city_info['city'],\n",
    "                    'state': city_info['state']\n",
    "                })\n",
    "        # Store the city-specific tree data in the dictionary\n",
    "        return city_tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b84526-4be1-4193-b23e-6ba451cd3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a preprocessor for heatmap data. We will be generating data for given cities against the common trees in all given cities.\n",
    "def processHeatMapFile(cities):\n",
    "    # Create a list of dictionaries for each tree species in the city\n",
    "    city_tree_dataList = []\n",
    "    city_tree_data = {city: {} for city in cities}\n",
    "    common_scientific_trees_list = []\n",
    "    for city in cities:\n",
    "        Filename = (glob.glob(\"Dataset/\" + city + \"*.csv\"))\n",
    "        data = pd.read_csv(Filename[0], usecols=IntrestingColumns) #use nrows paramter to limit the data if it consumes too much time to process\n",
    "        data.dropna(how='any', inplace=True)\n",
    "        if(not(data.empty)):\n",
    "            # Group data by scientific_name and get the count\n",
    "            tree_counts = data['scientific_name'].value_counts().to_dict()\n",
    "            \n",
    "            city_tree_data[city]=tree_counts\n",
    "            \n",
    "            keys_list = [set(inner_dict.keys()) for inner_dict in city_tree_data.values()]\n",
    "            \n",
    "            # Find the common keys (intersection) among all inner dictionaries\n",
    "            common_scientific_trees = set.intersection(*keys_list)\n",
    "            \n",
    "            common_scientific_trees_list = list(common_scientific_trees)\n",
    "    trees_to_keep = {city: {key: value for key, value in inner_dict.items() if key in common_scientific_trees_list} for city, inner_dict in city_tree_data.items()}\n",
    "    for city in cities:\n",
    "        Filename = (glob.glob(\"Dataset/\" + city + \"*.csv\"))\n",
    "        data = pd.read_csv(Filename[0], usecols=IntrestingColumns) #use nrows paramter to limit the data if it consumes too much time to process\n",
    "        data.dropna(how='any', inplace=True)\n",
    "        if(not(data.empty)):\n",
    "            \n",
    "            # Extract city and state information\n",
    "            city_info = data.iloc[0][['city', 'state']].to_dict()\n",
    "        \n",
    "            for scientific_name, count in trees_to_keep[city].items():\n",
    "                common_names = data[data['scientific_name'] == scientific_name]['common_name'].unique().tolist()\n",
    "                city_tree_dataList.append({\n",
    "                    \"city\" : city_info['city'],\n",
    "                    'scientific_name': scientific_name,\n",
    "                    'count': count,\n",
    "                    'common_name': common_names,\n",
    "                    'state': city_info['state']\n",
    "                })\n",
    "    return city_tree_dataList\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c0b6d5-9930-4e75-8235-06d69425aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the dataset of given cities and save them as unified json data with trees count grouped by city. Create the dropdown for cities for \n",
    "#which we have data for.\n",
    "\n",
    "# For the sake of data integrity, We will be dropping the rows which have null values\n",
    "# Set the city names you wish to get data for or for all cities insert \"All\"\n",
    "City = ['All'] \n",
    "\n",
    "tree_data_by_city = {}\n",
    "if(len(City)==1 and City[0] == 'All'):\n",
    "    for city in OnlyFilenames:\n",
    "        processedData =  processFile(city)\n",
    "        if(processedData is not None):\n",
    "            tree_data_by_city[city] = processedData\n",
    "        else:\n",
    "            OnlyFilenames.remove(city)\n",
    "    \n",
    "else:\n",
    "    for city in City:\n",
    "        processedData =  processFile(city)\n",
    "        if(processedData is not None):\n",
    "            tree_data_by_city[city] = processedData\n",
    "        else:\n",
    "            OnlyFilenames.remove(city)\n",
    "        \n",
    "tree_data_json = json.dumps(tree_data_by_city)\n",
    "\n",
    "with open(\"tree_data.json\", \"w\") as f:\n",
    "    f.write(tree_data_json)\n",
    "    \n",
    "#Step-4: Create JSON for city dropdown using extracted filenames\n",
    "cities= json.dumps({\"cities\": OnlyFilenames})\n",
    "f = open(\"city_dropdown.json\", \"w\")\n",
    "f.write(cities)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26b1a24-6aad-4082-a885-a3a3edde453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ailanthus altissima', 'Quercus rubra', 'Pyrus calleryana', 'Morus alba', 'Prunus cerasifera', 'Robinia pseudoacacia', 'Ulmus americana']\n"
     ]
    }
   ],
   "source": [
    "# Insert the cities names for which you want to get the data for heatmap. Remember that we will be generating data with common trees so it is possible\n",
    "# the you might get empty file.\n",
    "# Intresting fact:\n",
    "# No tree is common among all cities\n",
    "Cities = [\"Austin\",\"LosAngeles\",\"WashingtonDC\",\"Buffalo\",\"Boston\",\"Columbus\"] #,,\"Denver\",\"Houston\",\"NewYork\"\n",
    "#Cities = [\"All\"]\n",
    "csvHeaders = ['city','scientific_name','count','state','common_name'] \n",
    "if(len(Cities)==1 and Cities[0] == 'All'):\n",
    "    with open('heatmap.csv', 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames = csvHeaders)\n",
    "        writer.writeheader() \n",
    "        processedData =  processHeatMapFile(OnlyFilenames)\n",
    "        if(processedData is not None):\n",
    "            writer.writerows(processedData)\n",
    "    \n",
    "else:\n",
    "    with open('heatmap.csv', 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames = csvHeaders)\n",
    "        writer.writeheader() \n",
    "        processedData =  processHeatMapFile(Cities)\n",
    "        if(processedData is not None):\n",
    "            writer.writerows(processedData)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7e765-c8e7-4897-a68e-2611a596287e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38b8f4-c125-41ef-a727-cfb1f2e5abdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
